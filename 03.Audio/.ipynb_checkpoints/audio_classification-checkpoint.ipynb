{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Processing\n",
    "\n",
    "Thanks to Colin Jemmott for UC San Diego, October 2018\n",
    "\n",
    "Day 2:\n",
    "* DIY speaking recognition (silence versus talking)\n",
    "* IBM Open Source API for sound classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recorded Sounds\n",
    "\n",
    "Import `data/first_sound.wav` as an array using the provided code.  Then look at some statistics, including min, max, mean, and some raw samples.  Perhaps even plot it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import read\n",
    "import numpy as np\n",
    "\n",
    "# Read in wav file as an array\n",
    "a = read(\"data/first_sound.wav\")\n",
    "samplingRate = a[0]\n",
    "audioData = a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listen to audio from within the notebook using: `IPython.display.Audio`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "display.Audio(audioData, rate = samplingRate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Noise\n",
    "\n",
    "Add noise to the recording, matching the maximum value of the recording to the maximum value of the noise.  Then use the provided code to store it as a wav file.  Download it and listen -- or listen to it in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "audioWithNoise = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import write\n",
    "\n",
    "# Store the noise as a wav file\n",
    "scaled = np.int16(audioWithNoise/np.max(np.abs(audioWithNoise)) * 32767)\n",
    "write('output_with_noise.wav', 44100, scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Audio(scaled, rate = samplingRate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trim the quiet parts\n",
    "\n",
    "There are quite a few long pauses in the recording.  Using the first version, without the noise, write some code that will remove any pause longer than a half second.  Write down the wav file and see if it did what you thought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "trimmed = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = np.int16(trimmed/np.max(np.abs(trimmed)) * 32767)\n",
    "\n",
    "write('output_without_quiet.wav', 44100, scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Audio(scaled, rate = samplingRate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech recognition\n",
    "\n",
    "This uses IBM's [MAX Audio Classifier](https://github.com/IBM/MAX-Audio-Classifier) deployed to an [Azure Container Instance](https://azure.microsoft.com/en-us/services/container-instances/) on Microsoft's cloud.  It took me less than ten minutes to get the docker container running in the cloud.  The classifier is [open source](https://github.com/IBM/MAX-Audio-Classifier) so you can modify it.  Better yet, there are [lots of other free open source models from IBM](https://developer.ibm.com/exchanges/models/) also!\n",
    "\n",
    "You can read more about the ontology used for the training data [here](https://research.google.com/audioset/ontology/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#curl -F \"audio=@assets/thunder.wav\" -XPOST http://localhost:5000/model/predict\n",
    "\n",
    "fileName = \"data/first_sound.wav\"\n",
    "\n",
    "url = \"http://168.62.8.78:5000/model/predict\"\n",
    "files = {\"audio\":open(fileName, 'rb')}\n",
    "r = requests.post(url, files=files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now do the same thing with other wav files!  \n",
    "* What happens if you use the one where you added noise?\n",
    "* What happens if you take only a portion of an audio file?\n",
    "* What happens if you mix the recordings together? \n",
    "* What happens if you speed up / slow down the recordings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
